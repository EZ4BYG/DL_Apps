{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import glob \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices( device_type = 'GPU' )\n",
    "# 设置该程序可见的GPU：写到最前面！\n",
    "tf.config.experimental.set_visible_devices( devices = gpus[2:4], device_type = 'GPU' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 导入所有文件的路径："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有训练图片的地址：\n",
    "image_path = glob.glob( '/home/gaoboyu/学习数据集/沙漠数据集12_450/图像/*' )\n",
    "label_path = glob.glob( '/home/gaoboyu/学习数据集/沙漠数据集12_450/处理后标签/*' )\n",
    "# 排序：\n",
    "image_path.sort( key = lambda x:int(x.split('/')[-1].split('.')[0].split('_')[-1]) )\n",
    "label_path.sort( key = lambda x:int(x.split('/')[-1].split('.')[0].split('_')[-1]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 450)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_count = len(image_path)\n",
    "len(image_path), len(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 最后数据的乱序：\n",
    "index = np.random.permutation( image_count )\n",
    "image_path = np.array(image_path)[index]\n",
    "label_path = np.array(label_path)[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 创建数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices( (image_path, label_path) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90, 360)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 划分训练、测试集\n",
    "val_count = int( image_count*0.2 )\n",
    "train_count = image_count - val_count\n",
    "\n",
    "train_dataset = dataset.skip(val_count)  # 跳过前这么多数据\n",
    "val_dataset = dataset.take(val_count)   # 取前面这么多数据\n",
    "\n",
    "val_count, train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<SkipDataset shapes: ((), ()), types: (tf.string, tf.string)>,\n",
       " <TakeDataset shapes: ((), ()), types: (tf.string, tf.string)>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 查看：\n",
    "train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 预处理函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取图片：3通道\n",
    "def read_image(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels = 3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取标签：1通道（每个像素都是标签值）\n",
    "def read_label(path):\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_png(img, channels = 1)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对训练数据及标签：随机翻转 —— 训练数据专用！\n",
    "def random_flip(img, label):\n",
    "    img_label = tf.concat( [img, label], axis = -1 )  # 图像与标签合并\n",
    "    img_label = tf.image.resize(img_label, [256,256])\n",
    "    img_label = tf.image.random_flip_left_right(img_label)  # 随机左右翻转\n",
    "    img_label = tf.image.random_flip_up_down(img_label)     # 随机上下翻转\n",
    "    return img_label[:,:,0:3], img_label[:,:,3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 所有图像归一化 + 标签转数据类型：\n",
    "def normal(img, label):\n",
    "    img = tf.cast(img, tf.float32) / 127.5 - 1\n",
    "    label = tf.cast(label, tf.int32)  # 不能减1，因为里面本身就有0的标签！ \n",
    "    return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 训练数据加载：需要裁减！\n",
    "def load_train_image(img_path, label_path):\n",
    "    # 获取图片与标签：\n",
    "    img = read_image(img_path)\n",
    "    label = read_label(label_path)\n",
    "    # 预处理：随机翻转 —— 自带统一形状！\n",
    "    img, label = random_flip(img, label)\n",
    "    # 返回归一化：\n",
    "    return normal(img, label)\n",
    "\n",
    "def load_val_image(img_path, label_path):\n",
    "    # 获取图片与标签：\n",
    "    img = read_image(img_path)\n",
    "    label = read_label(label_path)\n",
    "    # 统一形状：\n",
    "    img = tf.image.resize(img, [256,256])\n",
    "    label = tf.image.resize(label, [256,256])\n",
    "    # 返回归一化：\n",
    "    return normal(img, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据应用于函数：\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE   # 多线程加载：图像加载是cpu处理的，cpu可以做多线程！\n",
    "\n",
    "train_dataset = train_dataset.map( load_train_image, num_parallel_calls = AUTOTUNE )\n",
    "val_dataset = val_dataset.map( load_val_image, num_parallel_calls = AUTOTUNE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<ParallelMapDataset shapes: ((256, 256, 3), (256, 256, 1)), types: (tf.float32, tf.int32)>,\n",
       " <ParallelMapDataset shapes: ((256, 256, 3), (256, 256, 1)), types: (tf.float32, tf.int32)>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 乱序、划分数据集：\n",
    "# cashe()：新操作，文件不断放到缓存中，加速！\n",
    "# prefetch()：新操作，GPU内存不等待，不断预处理图片\n",
    "BATCH_SIZE = 10\n",
    "train_dataset = train_dataset.cache().shuffle(train_count).repeat().batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 256, 256, 3), (None, 256, 256, 1)), types: (tf.float32, tf.int32)>,\n",
       " <BatchDataset shapes: ((None, 256, 256, 3), (None, 256, 256, 1)), types: (tf.float32, tf.int32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset, val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 使用预训练网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[3,3,512,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6f6e458443a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'model12_450_调过拟合.h5'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    182\u001b[0m     if (h5py is not None and (\n\u001b[1;32m    183\u001b[0m         isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     model = model_config_lib.model_from_config(model_config,\n\u001b[0;32m--> 178\u001b[0;31m                                                custom_objects=custom_objects)\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;31m# set weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/saving/model_config.py\u001b[0m in \u001b[0;36mmodel_from_config\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     53\u001b[0m                     '`Sequential.from_config(config)`?')\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdeserialize\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/layers/serialization.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m    107\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m       printable_module_name='layer')\n\u001b[0m",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    371\u001b[0m             custom_objects=dict(\n\u001b[1;32m    372\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_GLOBAL_CUSTOM_OBJECTS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m                 list(custom_objects.items())))\n\u001b[0m\u001b[1;32m    374\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mCustomObjectScope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mfrom_config\u001b[0;34m(cls, config, custom_objects)\u001b[0m\n\u001b[1;32m    985\u001b[0m     \"\"\"\n\u001b[1;32m    986\u001b[0m     input_tensors, output_tensors, created_layers = reconstruct_from_config(\n\u001b[0;32m--> 987\u001b[0;31m         config, custom_objects)\n\u001b[0m\u001b[1;32m    988\u001b[0m     model = cls(inputs=input_tensors, outputs=output_tensors,\n\u001b[1;32m    989\u001b[0m                 name=config.get('name'))\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mreconstruct_from_config\u001b[0;34m(config, custom_objects, created_layers)\u001b[0m\n\u001b[1;32m   2027\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2028\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mnode_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0munprocessed_nodes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2029\u001b[0;31m           \u001b[0mprocess_node\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2031\u001b[0m   \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mprocess_node\u001b[0;34m(layer, node_data)\u001b[0m\n\u001b[1;32m   1975\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput_tensors\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1976\u001b[0m       \u001b[0minput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnest_if_single_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1977\u001b[0;31m       \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1979\u001b[0m       \u001b[0;31m# Update node index map.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    895\u001b[0m           \u001b[0;31m# Build layer if applicable (if the `build` method has been\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    896\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 897\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    898\u001b[0m           \u001b[0mcast_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2414\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2415\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2416\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2417\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2418\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    575\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    578\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 743\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    744\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    745\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    139\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   def _variable_v2_call(cls,\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m                         shape=None):\n\u001b[1;32m    197\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2596\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2597\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2598\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2599\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2600\u001b[0m     return variables.RefVariable(\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1432\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1434\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1436\u001b[0m   def _init_from_args(self,\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1565\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1566\u001b[0m             initial_value = ops.convert_to_tensor(\n\u001b[0;32m-> 1567\u001b[0;31m                 \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1568\u001b[0m                 name=\"initial_value\", dtype=dtype)\n\u001b[1;32m   1569\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    119\u001b[0m         (type(init_ops.Initializer), type(init_ops_v2.Initializer))):\n\u001b[1;32m    120\u001b[0m       \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m     \u001b[0minit_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0mvariable_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0muse_resource\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype)\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1066\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m     return op(\n\u001b[0;32m-> 1068\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1069\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m       result = gen_random_ops.random_uniform(\n\u001b[0;32m--> 296\u001b[0;31m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    297\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaxval_is_one\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 724\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    725\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m   \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6651\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6652\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6653\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6654\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[3,3,512,1024] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model( 'model12_450_调过拟合.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络整体不可训练：\n",
    "model.trainable = False\n",
    "# 设定最后两个卷积层可训练：\n",
    "model.get_layer('dropout_x2_1').trainable = True\n",
    "model.get_layer('dropout_x2_2').trainable = True\n",
    "model.get_layer('dropout_x4_1').trainable = True\n",
    "model.get_layer('dropout_x4_2').trainable = True\n",
    "model.get_layer('dropout_x6_1').trainable = True\n",
    "model.get_layer('dropout_x6_2').trainable = True\n",
    "model.get_layer('dropout_x8_1').trainable = True\n",
    "model.get_layer('dropout_x8_1').trainable = True\n",
    "model.get_layer('dropout_x10_1').trainable = True\n",
    "model.get_layer('dropout_x10_2').trainable = True\n",
    "model.get_layer('output').trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型编译\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam( learning_rate = 0.001 / 5 ),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义保存模型的回调函数：保存整个模型、只保存最好的！\n",
    "# 设置保存的路径：\n",
    "checkpoint_path = '/home/gaoboyu/学习保存的模型/77'\n",
    "# 设置回调函数保存模型：没设置的参数都默认\n",
    "cp_callback_model = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_path,\n",
    "    monitor = 'val_acc',\n",
    "    save_best_only = True  # 监控的目标：如果新的epoch结果比前一个要好，那就重新保存最新的，删掉旧的！\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义动态学习速率调整：连续20个epoch都不提高，学习速率降低一半！\n",
    "cp_callback_lr = tf.keras.callbacks.ReduceLROnPlateau(\n",
    "    monitor = 'val_acc',\n",
    "    factor = 0.1,\n",
    "    patience = 20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1635 - acc: 0.9501WARNING:tensorflow:From /usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: /home/gaoboyu/学习保存的模型/77/assets\n",
      "36/36 [==============================] - 33s 905ms/step - loss: 0.1635 - acc: 0.9501 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 2/100\n",
      "36/36 [==============================] - 23s 653ms/step - loss: 0.1625 - acc: 0.9503 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 3/100\n",
      "36/36 [==============================] - 24s 653ms/step - loss: 0.1627 - acc: 0.9502 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 4/100\n",
      "36/36 [==============================] - 23s 650ms/step - loss: 0.1634 - acc: 0.9500 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 5/100\n",
      "36/36 [==============================] - 23s 648ms/step - loss: 0.1630 - acc: 0.9502 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "36/36 [==============================] - 23s 646ms/step - loss: 0.1638 - acc: 0.9500 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "36/36 [==============================] - 23s 644ms/step - loss: 0.1635 - acc: 0.9501 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "36/36 [==============================] - 23s 642ms/step - loss: 0.1631 - acc: 0.9502 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "36/36 [==============================] - 23s 640ms/step - loss: 0.1619 - acc: 0.9503 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "36/36 [==============================] - 23s 640ms/step - loss: 0.1628 - acc: 0.9501 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "36/36 [==============================] - 23s 639ms/step - loss: 0.1631 - acc: 0.9503 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 12/100\n",
      "36/36 [==============================] - 23s 639ms/step - loss: 0.1635 - acc: 0.9501 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 13/100\n",
      "36/36 [==============================] - 23s 639ms/step - loss: 0.1621 - acc: 0.9504 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 14/100\n",
      "36/36 [==============================] - 23s 638ms/step - loss: 0.1634 - acc: 0.9501 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 15/100\n",
      "36/36 [==============================] - 23s 640ms/step - loss: 0.1630 - acc: 0.9501 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 16/100\n",
      "36/36 [==============================] - 23s 638ms/step - loss: 0.1632 - acc: 0.9501 - val_loss: 0.1574 - val_acc: 0.9505 - lr: 2.0000e-04\n",
      "Epoch 17/100\n",
      "36/36 [==============================] - ETA: 0s - loss: 0.1639 - acc: 0.9500"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-1c51bfa76bfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_count\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# 回调函数：\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcp_callback_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcp_callback_lr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m )\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/Anaconda33/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 模型训练\n",
    "EPOCHES = 100\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = EPOCHES,\n",
    "    steps_per_epoch = train_count // BATCH_SIZE,\n",
    "    validation_data = val_dataset,\n",
    "    validation_steps = val_count // BATCH_SIZE,\n",
    "    # 回调函数：\n",
    "    callbacks = [cp_callback_model, cp_callback_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "history_path = '/home/gaoboyu/学习保存的模型/766/history.txt'\n",
    "with open(history_path, 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs = history.history.get('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将数据应用于函数：\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE   # 多线程加载：图像加载是cpu处理的，cpu可以做多线程！\n",
    "dataset = dataset.map( load_val_image, num_parallel_calls = AUTOTUNE )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 256, 256, 3), (None, 256, 256, 1)), types: (tf.float32, tf.int32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "dataset = dataset.cache().batch(BATCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = tf.keras.models.load_model( '/home/gaoboyu/学习保存的模型dataset漠11_8x8_2' )\n",
    "model = tf.keras.models.load_model( 'model12_450_调过拟合.h5' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 4s 399ms/step - loss: 0.1807 - acc: 0.9498\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.18072709441184998, 0.9497509598731995]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 141/170\n",
      "36/36 [==============================] - 59s 2s/step - loss: 0.0789 - acc: 0.9655 - val_loss: 0.1807 - val_acc: 0.9445\n",
      "Epoch 142/170\n",
      "36/36 [==============================] - 59s 2s/step - loss: 0.0770 - acc: 0.9664 - val_loss: 0.1745 - val_acc: 0.9451\n",
      "Epoch 143/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0757 - acc: 0.9669 - val_loss: 0.1606 - val_acc: 0.9469\n",
      "Epoch 144/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0762 - acc: 0.9667 - val_loss: 0.1723 - val_acc: 0.9460\n",
      "Epoch 145/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0809 - acc: 0.9645 - val_loss: 0.1734 - val_acc: 0.9439\n",
      "Epoch 146/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0768 - acc: 0.9665 - val_loss: 0.1633 - val_acc: 0.9441\n",
      "Epoch 147/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0768 - acc: 0.9665 - val_loss: 0.1730 - val_acc: 0.9451\n",
      "Epoch 148/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0764 - acc: 0.9666 - val_loss: 0.1678 - val_acc: 0.9461\n",
      "Epoch 149/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0751 - acc: 0.9672 - val_loss: 0.1753 - val_acc: 0.9453\n",
      "Epoch 150/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0756 - acc: 0.9670 - val_loss: 0.1743 - val_acc: 0.9471\n",
      "Epoch 151/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0751 - acc: 0.9672 - val_loss: 0.1607 - val_acc: 0.9465\n",
      "Epoch 152/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0733 - acc: 0.9680 - val_loss: 0.1702 - val_acc: 0.9457\n",
      "Epoch 153/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0725 - acc: 0.9684 - val_loss: 0.1826 - val_acc: 0.9454\n",
      "Epoch 154/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0723 - acc: 0.9683 - val_loss: 0.1766 - val_acc: 0.9464\n",
      "Epoch 155/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0729 - acc: 0.9682 - val_loss: 0.1673 - val_acc: 0.9467\n",
      "Epoch 156/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0734 - acc: 0.9679 - val_loss: 0.1683 - val_acc: 0.9464\n",
      "Epoch 157/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0716 - acc: 0.9687 - val_loss: 0.1719 - val_acc: 0.9472\n",
      "Epoch 158/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0729 - acc: 0.9681 - val_loss: 0.1587 - val_acc: 0.9477\n",
      "Epoch 159/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0723 - acc: 0.9685 - val_loss: 0.1646 - val_acc: 0.9471\n",
      "Epoch 160/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0729 - acc: 0.9682 - val_loss: 0.1561 - val_acc: 0.9471\n",
      "Epoch 161/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0714 - acc: 0.9688 - val_loss: 0.1878 - val_acc: 0.9443\n",
      "Epoch 162/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0712 - acc: 0.9689 - val_loss: 0.1863 - val_acc: 0.9438\n",
      "Epoch 163/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0695 - acc: 0.9696 - val_loss: 0.1789 - val_acc: 0.9478\n",
      "Epoch 164/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0694 - acc: 0.9697 - val_loss: 0.1637 - val_acc: 0.9480\n",
      "Epoch 165/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0699 - acc: 0.9695 - val_loss: 0.1890 - val_acc: 0.9462\n",
      "Epoch 166/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0695 - acc: 0.9697 - val_loss: 0.1700 - val_acc: 0.9465\n",
      "Epoch 167/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0684 - acc: 0.9702 - val_loss: 0.1680 - val_acc: 0.9474\n",
      "Epoch 168/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0690 - acc: 0.9699 - val_loss: 0.1707 - val_acc: 0.9469\n",
      "Epoch 169/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0683 - acc: 0.9702 - val_loss: 0.1721 - val_acc: 0.9471\n",
      "Epoch 170/170\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0673 - acc: 0.9707 - val_loss: 0.1756 - val_acc: 0.9467\n"
     ]
    }
   ],
   "source": [
    "# 降速训练1（0.0001）：再次编译 + 再次训练\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam( lr = 0.001 ),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "\n",
    "# 再次训练：\n",
    "initial_epochs = EPOCHES\n",
    "final_epochs = 30  # 再多训练10个epoch\n",
    "total_epochs = initial_epochs + final_epochs\n",
    "\n",
    "history1 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = total_epochs,\n",
    "    initial_epoch = initial_epochs,  # 数值从initial_epochs开始记录而已！\n",
    "    steps_per_epoch = train_count // BATCH_SIZE,\n",
    "    validation_data = val_dataset,\n",
    "    validation_steps = val_count // BATCH_SIZE,\n",
    "    # 回调函数：\n",
    "    callbacks = [cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "history_path = '/home/gaoboyu/学习保存的模型/75/history1.txt'\n",
    "with open(history_path, 'wb') as file_pi:\n",
    "    pickle.dump(history1.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cs = history1.history.get('loss')\n",
    "len(cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 171/200\n",
      "36/36 [==============================] - 60s 2s/step - loss: 0.0684 - acc: 0.9702 - val_loss: 0.1630 - val_acc: 0.9465\n",
      "Epoch 172/200\n",
      "36/36 [==============================] - 59s 2s/step - loss: 0.0673 - acc: 0.9707 - val_loss: 0.1787 - val_acc: 0.9467\n",
      "Epoch 173/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0670 - acc: 0.9708 - val_loss: 0.1763 - val_acc: 0.9454\n",
      "Epoch 174/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0685 - acc: 0.9702 - val_loss: 0.1715 - val_acc: 0.9459\n",
      "Epoch 175/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0664 - acc: 0.9710 - val_loss: 0.1774 - val_acc: 0.9443\n",
      "Epoch 176/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0680 - acc: 0.9703 - val_loss: 0.1825 - val_acc: 0.9462\n",
      "Epoch 177/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0662 - acc: 0.9711 - val_loss: 0.1762 - val_acc: 0.9478\n",
      "Epoch 178/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0664 - acc: 0.9711 - val_loss: 0.1718 - val_acc: 0.9462\n",
      "Epoch 179/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0657 - acc: 0.9713 - val_loss: 0.1652 - val_acc: 0.9469\n",
      "Epoch 180/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0666 - acc: 0.9710 - val_loss: 0.1756 - val_acc: 0.9451\n",
      "Epoch 181/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0658 - acc: 0.9714 - val_loss: 0.1734 - val_acc: 0.9478\n",
      "Epoch 182/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0639 - acc: 0.9721 - val_loss: 0.1762 - val_acc: 0.9470\n",
      "Epoch 183/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0644 - acc: 0.9719 - val_loss: 0.1841 - val_acc: 0.9471\n",
      "Epoch 184/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0640 - acc: 0.9721 - val_loss: 0.1816 - val_acc: 0.9471\n",
      "Epoch 185/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0635 - acc: 0.9723 - val_loss: 0.1851 - val_acc: 0.9475\n",
      "Epoch 186/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0630 - acc: 0.9725 - val_loss: 0.1807 - val_acc: 0.9475\n",
      "Epoch 187/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0631 - acc: 0.9725 - val_loss: 0.1840 - val_acc: 0.9471\n",
      "Epoch 188/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0641 - acc: 0.9721 - val_loss: 0.1765 - val_acc: 0.9463\n",
      "Epoch 189/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0635 - acc: 0.9723 - val_loss: 0.1824 - val_acc: 0.9471\n",
      "Epoch 190/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0636 - acc: 0.9724 - val_loss: 0.1718 - val_acc: 0.9473\n",
      "Epoch 191/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0660 - acc: 0.9711 - val_loss: 0.1765 - val_acc: 0.9464\n",
      "Epoch 192/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0649 - acc: 0.9717 - val_loss: 0.1776 - val_acc: 0.9438\n",
      "Epoch 193/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0625 - acc: 0.9728 - val_loss: 0.1785 - val_acc: 0.9472\n",
      "Epoch 194/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0630 - acc: 0.9726 - val_loss: 0.1873 - val_acc: 0.9464\n",
      "Epoch 195/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0622 - acc: 0.9729 - val_loss: 0.1832 - val_acc: 0.9473\n",
      "Epoch 196/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0624 - acc: 0.9728 - val_loss: 0.1895 - val_acc: 0.9468\n",
      "Epoch 197/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0615 - acc: 0.9732 - val_loss: 0.1861 - val_acc: 0.9457\n",
      "Epoch 198/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0611 - acc: 0.9734 - val_loss: 0.1790 - val_acc: 0.9473\n",
      "Epoch 199/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0602 - acc: 0.9738 - val_loss: 0.1882 - val_acc: 0.9477\n",
      "Epoch 200/200\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0601 - acc: 0.9738 - val_loss: 0.1836 - val_acc: 0.9471\n"
     ]
    }
   ],
   "source": [
    "# 降速训练1（0.001）：再次编译 + 再次训练\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam( lr = 0.001 ),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "\n",
    "# 再次训练：\n",
    "initial_epochs = total_epochs\n",
    "final_epochs = 30  # 再多训练10个epoch\n",
    "total_epochs = initial_epochs + final_epochs\n",
    "\n",
    "history2 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = total_epochs,\n",
    "    initial_epoch = initial_epochs,  # 数值从initial_epochs开始记录而已！\n",
    "    steps_per_epoch = train_count // BATCH_SIZE,\n",
    "    validation_data = val_dataset,\n",
    "    validation_steps = val_count // BATCH_SIZE,\n",
    "    # 回调函数：\n",
    "    callbacks = [cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "history_path = '/home/gaoboyu/学习保存的模型/75/history2.txt'\n",
    "with open(history_path, 'wb') as file_pi:\n",
    "    pickle.dump(history2.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 201/250\n",
      "36/36 [==============================] - 59s 2s/step - loss: 0.0580 - acc: 0.9748 - val_loss: 0.1862 - val_acc: 0.9480\n",
      "Epoch 202/250\n",
      "36/36 [==============================] - 59s 2s/step - loss: 0.0568 - acc: 0.9753 - val_loss: 0.1846 - val_acc: 0.9479\n",
      "Epoch 203/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0570 - acc: 0.9752 - val_loss: 0.1886 - val_acc: 0.9477\n",
      "Epoch 204/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0563 - acc: 0.9755 - val_loss: 0.1896 - val_acc: 0.9477\n",
      "Epoch 205/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0560 - acc: 0.9756 - val_loss: 0.1891 - val_acc: 0.9479\n",
      "Epoch 206/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0560 - acc: 0.9756 - val_loss: 0.1866 - val_acc: 0.9480\n",
      "Epoch 207/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0560 - acc: 0.9757 - val_loss: 0.1898 - val_acc: 0.9478\n",
      "Epoch 208/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0558 - acc: 0.9757 - val_loss: 0.1938 - val_acc: 0.9473\n",
      "Epoch 209/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0553 - acc: 0.9759 - val_loss: 0.1957 - val_acc: 0.9473\n",
      "Epoch 210/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0553 - acc: 0.9759 - val_loss: 0.1894 - val_acc: 0.9481\n",
      "Epoch 211/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0551 - acc: 0.9760 - val_loss: 0.1893 - val_acc: 0.9478\n",
      "Epoch 212/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0549 - acc: 0.9761 - val_loss: 0.1910 - val_acc: 0.9478\n",
      "Epoch 213/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0548 - acc: 0.9762 - val_loss: 0.1908 - val_acc: 0.9476\n",
      "Epoch 214/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0549 - acc: 0.9761 - val_loss: 0.1921 - val_acc: 0.9477\n",
      "Epoch 215/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0544 - acc: 0.9763 - val_loss: 0.1949 - val_acc: 0.9475\n",
      "Epoch 216/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0542 - acc: 0.9764 - val_loss: 0.1938 - val_acc: 0.9476\n",
      "Epoch 217/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0540 - acc: 0.9765 - val_loss: 0.1918 - val_acc: 0.9477\n",
      "Epoch 218/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0539 - acc: 0.9765 - val_loss: 0.1912 - val_acc: 0.9477\n",
      "Epoch 219/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0541 - acc: 0.9765 - val_loss: 0.1899 - val_acc: 0.9474\n",
      "Epoch 220/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0540 - acc: 0.9765 - val_loss: 0.1929 - val_acc: 0.9477\n",
      "Epoch 221/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0538 - acc: 0.9766 - val_loss: 0.1907 - val_acc: 0.9479\n",
      "Epoch 222/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0536 - acc: 0.9767 - val_loss: 0.1956 - val_acc: 0.9481\n",
      "Epoch 223/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0537 - acc: 0.9767 - val_loss: 0.1956 - val_acc: 0.9480\n",
      "Epoch 224/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0534 - acc: 0.9768 - val_loss: 0.1904 - val_acc: 0.9482\n",
      "Epoch 225/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0535 - acc: 0.9767 - val_loss: 0.1940 - val_acc: 0.9480\n",
      "Epoch 226/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0533 - acc: 0.9768 - val_loss: 0.1974 - val_acc: 0.9479\n",
      "Epoch 227/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0531 - acc: 0.9769 - val_loss: 0.1974 - val_acc: 0.9478\n",
      "Epoch 228/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0532 - acc: 0.9769 - val_loss: 0.1928 - val_acc: 0.9480\n",
      "Epoch 229/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0532 - acc: 0.9769 - val_loss: 0.1958 - val_acc: 0.9478\n",
      "Epoch 230/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0526 - acc: 0.9771 - val_loss: 0.1960 - val_acc: 0.9477\n",
      "Epoch 231/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0529 - acc: 0.9770 - val_loss: 0.1999 - val_acc: 0.9477\n",
      "Epoch 232/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0530 - acc: 0.9769 - val_loss: 0.1929 - val_acc: 0.9480\n",
      "Epoch 233/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0528 - acc: 0.9770 - val_loss: 0.1963 - val_acc: 0.9478\n",
      "Epoch 234/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0526 - acc: 0.9771 - val_loss: 0.1967 - val_acc: 0.9477\n",
      "Epoch 235/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0524 - acc: 0.9772 - val_loss: 0.2025 - val_acc: 0.9476\n",
      "Epoch 236/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0523 - acc: 0.9773 - val_loss: 0.2003 - val_acc: 0.9473\n",
      "Epoch 237/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0525 - acc: 0.9772 - val_loss: 0.1979 - val_acc: 0.9473\n",
      "Epoch 238/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0521 - acc: 0.9773 - val_loss: 0.1982 - val_acc: 0.9477\n",
      "Epoch 239/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0520 - acc: 0.9774 - val_loss: 0.2007 - val_acc: 0.9480\n",
      "Epoch 240/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0522 - acc: 0.9773 - val_loss: 0.2012 - val_acc: 0.9476\n",
      "Epoch 241/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0520 - acc: 0.9774 - val_loss: 0.2022 - val_acc: 0.9476\n",
      "Epoch 242/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0519 - acc: 0.9774 - val_loss: 0.2007 - val_acc: 0.9476\n",
      "Epoch 243/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0518 - acc: 0.9775 - val_loss: 0.2024 - val_acc: 0.9473\n",
      "Epoch 244/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0517 - acc: 0.9775 - val_loss: 0.2051 - val_acc: 0.9471\n",
      "Epoch 245/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0518 - acc: 0.9775 - val_loss: 0.2037 - val_acc: 0.9471\n",
      "Epoch 246/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0514 - acc: 0.9777 - val_loss: 0.2044 - val_acc: 0.9472\n",
      "Epoch 247/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0516 - acc: 0.9776 - val_loss: 0.2009 - val_acc: 0.9474\n",
      "Epoch 248/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0516 - acc: 0.9776 - val_loss: 0.1991 - val_acc: 0.9476\n",
      "Epoch 249/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0510 - acc: 0.9778 - val_loss: 0.2028 - val_acc: 0.9474\n",
      "Epoch 250/250\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0509 - acc: 0.9779 - val_loss: 0.2037 - val_acc: 0.9477\n"
     ]
    }
   ],
   "source": [
    "# 降速训练1（0.001）：再次编译 + 再次训练\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam( lr = 0.001 / 5 ),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "\n",
    "# 再次训练：\n",
    "initial_epochs = total_epochs\n",
    "final_epochs = 50  # 再多训练10个epoch\n",
    "total_epochs = initial_epochs + final_epochs\n",
    "\n",
    "history3 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = total_epochs,\n",
    "    initial_epoch = initial_epochs,  # 数值从initial_epochs开始记录而已！\n",
    "    steps_per_epoch = train_count // BATCH_SIZE,\n",
    "    validation_data = val_dataset,\n",
    "    validation_steps = val_count // BATCH_SIZE,\n",
    "    # 回调函数：\n",
    "    callbacks = [cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "history_path = '/home/gaoboyu/学习保存的模型/75/history3.txt'\n",
    "with open(history_path, 'wb') as file_pi:\n",
    "    pickle.dump(history3.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 251/300\n",
      "36/36 [==============================] - 60s 2s/step - loss: 0.0510 - acc: 0.9779 - val_loss: 0.2016 - val_acc: 0.9477\n",
      "Epoch 252/300\n",
      "36/36 [==============================] - 59s 2s/step - loss: 0.0508 - acc: 0.9779 - val_loss: 0.2044 - val_acc: 0.9476\n",
      "Epoch 253/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0506 - acc: 0.9781 - val_loss: 0.2043 - val_acc: 0.9477\n",
      "Epoch 254/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0508 - acc: 0.9779 - val_loss: 0.2025 - val_acc: 0.9476\n",
      "Epoch 255/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0503 - acc: 0.9781 - val_loss: 0.2058 - val_acc: 0.9474\n",
      "Epoch 256/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0504 - acc: 0.9781 - val_loss: 0.2040 - val_acc: 0.9474\n",
      "Epoch 257/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0503 - acc: 0.9782 - val_loss: 0.2042 - val_acc: 0.9476\n",
      "Epoch 258/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0504 - acc: 0.9781 - val_loss: 0.2013 - val_acc: 0.9477\n",
      "Epoch 259/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0504 - acc: 0.9781 - val_loss: 0.2019 - val_acc: 0.9478\n",
      "Epoch 260/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0503 - acc: 0.9781 - val_loss: 0.2038 - val_acc: 0.9476\n",
      "Epoch 261/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0504 - acc: 0.9781 - val_loss: 0.2032 - val_acc: 0.9475\n",
      "Epoch 262/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0503 - acc: 0.9782 - val_loss: 0.2043 - val_acc: 0.9475\n",
      "Epoch 263/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0501 - acc: 0.9782 - val_loss: 0.2025 - val_acc: 0.9474\n",
      "Epoch 264/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0500 - acc: 0.9783 - val_loss: 0.2061 - val_acc: 0.9473\n",
      "Epoch 265/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0502 - acc: 0.9782 - val_loss: 0.2048 - val_acc: 0.9474\n",
      "Epoch 266/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0500 - acc: 0.9783 - val_loss: 0.2026 - val_acc: 0.9475\n",
      "Epoch 267/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0502 - acc: 0.9782 - val_loss: 0.2039 - val_acc: 0.9474\n",
      "Epoch 268/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0500 - acc: 0.9783 - val_loss: 0.2053 - val_acc: 0.9474\n",
      "Epoch 269/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0503 - acc: 0.9782 - val_loss: 0.2028 - val_acc: 0.9476\n",
      "Epoch 270/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0498 - acc: 0.9784 - val_loss: 0.2049 - val_acc: 0.9476\n",
      "Epoch 271/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0497 - acc: 0.9784 - val_loss: 0.2058 - val_acc: 0.9477\n",
      "Epoch 272/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0498 - acc: 0.9784 - val_loss: 0.2071 - val_acc: 0.9474\n",
      "Epoch 273/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0499 - acc: 0.9783 - val_loss: 0.2047 - val_acc: 0.9475\n",
      "Epoch 274/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0496 - acc: 0.9785 - val_loss: 0.2093 - val_acc: 0.9473\n",
      "Epoch 275/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0499 - acc: 0.9783 - val_loss: 0.2052 - val_acc: 0.9475\n",
      "Epoch 276/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0497 - acc: 0.9784 - val_loss: 0.2081 - val_acc: 0.9473\n",
      "Epoch 277/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0497 - acc: 0.9784 - val_loss: 0.2078 - val_acc: 0.9474\n",
      "Epoch 278/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0498 - acc: 0.9784 - val_loss: 0.2092 - val_acc: 0.9474\n",
      "Epoch 279/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0497 - acc: 0.9784 - val_loss: 0.2099 - val_acc: 0.9473\n",
      "Epoch 280/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0495 - acc: 0.9785 - val_loss: 0.2074 - val_acc: 0.9475\n",
      "Epoch 281/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0496 - acc: 0.9785 - val_loss: 0.2069 - val_acc: 0.9477\n",
      "Epoch 282/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0494 - acc: 0.9785 - val_loss: 0.2057 - val_acc: 0.9479\n",
      "Epoch 283/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0495 - acc: 0.9785 - val_loss: 0.2051 - val_acc: 0.9478\n",
      "Epoch 284/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0492 - acc: 0.9786 - val_loss: 0.2061 - val_acc: 0.9476\n",
      "Epoch 285/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0493 - acc: 0.9786 - val_loss: 0.2099 - val_acc: 0.9474\n",
      "Epoch 286/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0494 - acc: 0.9785 - val_loss: 0.2033 - val_acc: 0.9477\n",
      "Epoch 287/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0491 - acc: 0.9787 - val_loss: 0.2037 - val_acc: 0.9477\n",
      "Epoch 288/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0490 - acc: 0.9787 - val_loss: 0.2064 - val_acc: 0.9474\n",
      "Epoch 289/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0492 - acc: 0.9787 - val_loss: 0.2074 - val_acc: 0.9475\n",
      "Epoch 290/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0489 - acc: 0.9788 - val_loss: 0.2032 - val_acc: 0.9476\n",
      "Epoch 291/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0489 - acc: 0.9788 - val_loss: 0.2073 - val_acc: 0.9476\n",
      "Epoch 292/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0492 - acc: 0.9786 - val_loss: 0.2071 - val_acc: 0.9477\n",
      "Epoch 293/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0491 - acc: 0.9787 - val_loss: 0.2081 - val_acc: 0.9478\n",
      "Epoch 294/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0490 - acc: 0.9787 - val_loss: 0.2116 - val_acc: 0.9475\n",
      "Epoch 295/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0489 - acc: 0.9788 - val_loss: 0.2096 - val_acc: 0.9477\n",
      "Epoch 296/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0487 - acc: 0.9789 - val_loss: 0.2085 - val_acc: 0.9476\n",
      "Epoch 297/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0487 - acc: 0.9789 - val_loss: 0.2089 - val_acc: 0.9476\n",
      "Epoch 298/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0488 - acc: 0.9788 - val_loss: 0.2118 - val_acc: 0.9474\n",
      "Epoch 299/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0486 - acc: 0.9789 - val_loss: 0.2079 - val_acc: 0.9475\n",
      "Epoch 300/300\n",
      "36/36 [==============================] - 58s 2s/step - loss: 0.0487 - acc: 0.9788 - val_loss: 0.2083 - val_acc: 0.9476\n"
     ]
    }
   ],
   "source": [
    "# 降速训练1（0.001）：再次编译 + 再次训练\n",
    "model.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam( lr = 0.0001 ),\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['acc']\n",
    ")\n",
    "\n",
    "# 再次训练：\n",
    "initial_epochs = total_epochs\n",
    "final_epochs = 50  # 再多训练10个epoch\n",
    "total_epochs = initial_epochs + final_epochs\n",
    "\n",
    "history4 = model.fit(\n",
    "    train_dataset,\n",
    "    epochs = total_epochs,\n",
    "    initial_epoch = initial_epochs,  # 数值从initial_epochs开始记录而已！\n",
    "    steps_per_epoch = train_count // BATCH_SIZE,\n",
    "    validation_data = val_dataset,\n",
    "    validation_steps = val_count // BATCH_SIZE,\n",
    "    # 回调函数：\n",
    "    callbacks = [cp_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_path = '/home/gaoboyu/学习保存的模型/75/history4.txt'\n",
    "with open(history_path, 'wb') as file_pi:\n",
    "    pickle.dump(history4.history, file_pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
